{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77513339-4974-4e08-8397-4ded93a9a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataPrep\n",
    "import FeatureSelection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8b4bf1-7787-4b11-b94b-923b0246492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#string to test\n",
    "doc_new = ['obama is running for president in 2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83def56f-b0d2-49a7-beb5-02661dcf7dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the feature selection has been done in FeatureSelection.py module. here we will create models using those features for prediction\n",
    "\n",
    "#first we will use bag of words techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c96c536-f266-4339-9c58-d06bfe9b70d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6072128577028616"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building classifier using naive bayes \n",
    "nb_pipeline = Pipeline([\n",
    "        ('NBCV',FeatureSelection.countV),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_nb = nb_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_nb == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5365562-05e8-4ca1-b76e-da58b5a03e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6013328106624853"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building classifier using logistic regression\n",
    "logR_pipeline = Pipeline([\n",
    "        ('LogRCV',FeatureSelection.countV),\n",
    "        ('LogR_clf',LogisticRegression())\n",
    "        ])\n",
    "logR_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR = logR_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b0c799d-5cf4-4b60-b3d2-fc5d2cdcf327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5723245785966288"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building Linear SVM classfier\n",
    "svm_pipeline = Pipeline([\n",
    "        ('svmCV',FeatureSelection.countV),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_svm = svm_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_svm == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3232577a-ac8c-4c2f-9e9e-de51652cd90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6087808702469619"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using SVM Stochastic Gradient Descent on hinge loss\n",
    "sgd_pipeline = Pipeline([\n",
    "        ('svm2CV',FeatureSelection.countV),\n",
    "        ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5))\n",
    "        ])\n",
    "\n",
    "sgd_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_sgd == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ea5bff-7b68-466a-8100-4301dffd7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6256370050960408"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random forest\n",
    "random_forest = Pipeline([\n",
    "        ('rfCV',FeatureSelection.countV),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_rf = random_forest.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_rf == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46fa5a3f-247a-4b35-b173-6e7f57d6466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined functon for K-Fold cross validatoin\n",
    "def build_confusion_matrix(classifier):\n",
    "    \n",
    "    k_fold = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "\n",
    "    for train_ind, test_ind in k_fold.split(DataPrep.train_news):\n",
    "        train_text = DataPrep.train_news.iloc[train_ind]['Statement'] \n",
    "        train_y = DataPrep.train_news.iloc[train_ind]['Label']\n",
    "    \n",
    "        test_text = DataPrep.train_news.iloc[test_ind]['Statement']\n",
    "        test_y = DataPrep.train_news.iloc[test_ind]['Label']\n",
    "        \n",
    "        classifier.fit(train_text,train_y)\n",
    "        predictions = classifier.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y,predictions)\n",
    "        score = f1_score(test_y,predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return (print('Total statements classified:', len(DataPrep.train_news)),\n",
    "    print('Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7201c6c-05e1-4e3b-9096-c167792fe30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.66961153965076\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2118 2370]\n",
      " [1664 4088]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-fold cross validation for all classifiers\n",
    "build_confusion_matrix(nb_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3c9de43-aa08-4b4a-ae9d-a734d05d3640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6470221003039508\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2252 2236]\n",
      " [1932 3820]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(logR_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54457b66-61d2-4997-8469-67e54d64f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6104687487924284\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2260 2228]\n",
      " [2246 3506]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(svm_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fef20be-4b49-4270-9a48-e9d31dccb6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6563223294384912\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2115 2373]\n",
      " [1781 3971]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(sgd_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f3456e-de25-465b-9b13-82d41ce4f2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.700337510384436\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1808 2680]\n",
      " [1208 4544]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "340d6db7-c1f2-419c-ac83-7cb93e9b0ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5938847510780086\n",
      "0.6185809486475892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6170129361034888\n",
      "0.5417483339866719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"So far we have used bag of words technique to extract the features and passed those featuers into classifiers. We have also seen the\n",
    "f1 scores of these classifiers. now lets enhance these features using term frequency weights with various n-grams\n",
    "\"\"\"\n",
    "\n",
    "##Now using n-grams\n",
    "#naive-bayes classifier\n",
    "nb_pipeline_ngram = Pipeline([\n",
    "        ('nb_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_nb_ngram = nb_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "print(np.mean(predicted_nb_ngram == DataPrep.test_news['Label']))\n",
    "\n",
    "\n",
    "#logistic regression classifier\n",
    "logR_pipeline_ngram = Pipeline([\n",
    "        ('LogR_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR_ngram = logR_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "print(np.mean(predicted_LogR_ngram == DataPrep.test_news['Label']))\n",
    "\n",
    "\n",
    "#linear SVM classifier\n",
    "svm_pipeline_ngram = Pipeline([\n",
    "        ('svm_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_svm_ngram = svm_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "print(np.mean(predicted_svm_ngram == DataPrep.test_news['Label']))\n",
    "\n",
    "\n",
    "#sgd classifier\n",
    "sgd_pipeline_ngram = Pipeline([\n",
    "         ('sgd_tfidf',FeatureSelection.tfidf_ngram),\n",
    "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, max_iter=5))\n",
    "         ])\n",
    "\n",
    "sgd_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_sgd_ngram = sgd_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "print(np.mean(predicted_sgd_ngram == DataPrep.test_news['Label']))\n",
    "\n",
    "\n",
    "#random forest classifier\n",
    "# random_forest_ngram = Pipeline([\n",
    "#         ('rf_tfidf',FeatureSelection.tfidf_ngram),\n",
    "#         ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
    "#         ])\n",
    "    \n",
    "# random_forest_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "# predicted_rf_ngram = random_forest_ngram.predict(DataPrep.test_news['Statement'])\n",
    "# print(np.mean(predicted_rf_ngram == DataPrep.test_news['Label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14d14a72-dc83-4b63-b3a5-4b336dc55c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7224053159841455\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[ 758 3730]\n",
      " [ 390 5362]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(nb_pipeline_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3383dff5-5f69-4628-b8e1-d05058263dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7042876638233403\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1581 2907]\n",
      " [1045 4707]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(logR_pipeline_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b54fb42-529f-48f9-84dc-32afa2e3b9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6790920142902143\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2016 2472]\n",
      " [1524 4228]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(svm_pipeline_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0612761-e87e-425a-8f30-ab2454dd48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7190643331130575\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[   5 4483]\n",
      " [   6 5746]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(sgd_pipeline_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce0d68d-5c44-4224-b763-4cda4ecaff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_confusion_matrix(random_forest_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e25f008-74cc-4490-be88-33ecdbf4bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.19      0.30      1169\n",
      "        True       0.58      0.94      0.71      1382\n",
      "\n",
      "    accuracy                           0.59      2551\n",
      "   macro avg       0.65      0.56      0.51      2551\n",
      "weighted avg       0.64      0.59      0.52      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.39      0.48      1169\n",
      "        True       0.61      0.81      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.47      0.53      1169\n",
      "        True       0.62      0.74      0.68      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.61      0.61      0.60      2551\n",
      "weighted avg       0.62      0.62      0.61      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1169\n",
      "        True       0.54      1.00      0.70      1382\n",
      "\n",
      "    accuracy                           0.54      2551\n",
      "   macro avg       0.27      0.50      0.35      2551\n",
      "weighted avg       0.29      0.54      0.38      2551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(DataPrep.test_news['Label'], predicted_nb_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_LogR_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_svm_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_sgd_ngram))\n",
    "# print(classification_report(DataPrep.test_news['Label'], predicted_rf_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48d4860c-a27a-4760-858b-ffbbaff82000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2551,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
    "from the confusion matrix, we can see that random forest and logistic regression are best performing \n",
    "in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
    "to be low compared to rest of the models)\n",
    "\"\"\"\n",
    "DataPrep.test_news['Label'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "483da739-9940-42dc-a9c5-bfc086bdc8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #grid-search parameter optimization\n",
    "# #random forest classifier parameters\n",
    "# parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "#                'rf_tfidf__use_idf': (True, False),\n",
    "#                'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "# }\n",
    "\n",
    "# gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "# gs_clf.best_score_\n",
    "# gs_clf.best_params_\n",
    "# gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5c75361-76aa-45c8-a509-6aafe35f6c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.51498618, 0.50580206, 0.55451908, 0.48259206, 1.49758472,\n",
       "        1.91337743, 1.94042358, 1.81324525, 2.67262216, 2.68769445,\n",
       "        2.13458819, 2.7334024 , 3.70294614, 3.68034873, 2.99725838,\n",
       "        3.30808096, 3.8788918 , 4.4731307 , 3.627105  , 3.96107297]),\n",
       " 'std_fit_time': array([0.07249428, 0.02747269, 0.02912707, 0.02610611, 0.04418004,\n",
       "        0.17885938, 0.14435783, 0.26637263, 0.22289564, 0.16804268,\n",
       "        0.14615459, 0.22147051, 0.45260204, 0.18330022, 0.12727933,\n",
       "        0.20124522, 0.3694826 , 0.48983952, 0.11738111, 0.39265556]),\n",
       " 'mean_score_time': array([0.09186759, 0.08498287, 0.09085588, 0.08237467, 0.15127215,\n",
       "        0.20047255, 0.17806821, 0.13675938, 0.17253098, 0.17034907,\n",
       "        0.17408266, 0.17356949, 0.29385829, 0.19976573, 0.19039807,\n",
       "        0.18326821, 0.23344555, 0.20095205, 0.20960693, 0.18896599]),\n",
       " 'std_score_time': array([0.01451422, 0.01699036, 0.00718271, 0.01012486, 0.02639695,\n",
       "        0.03359004, 0.04411491, 0.01564117, 0.01172496, 0.01570807,\n",
       "        0.01410673, 0.01543491, 0.09202477, 0.02888711, 0.00376555,\n",
       "        0.01515616, 0.01310367, 0.01358587, 0.01451361, 0.04571802]),\n",
       " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.6105, 0.6205, 0.6115, 0.6205, 0.6195, 0.6165, 0.6185, 0.6165,\n",
       "        0.621 , 0.618 , 0.621 , 0.618 , 0.6155, 0.6145, 0.6165, 0.6145,\n",
       "        0.6155, 0.6135, 0.613 , 0.6135]),\n",
       " 'split1_test_score': array([0.619 , 0.621 , 0.619 , 0.621 , 0.625 , 0.6235, 0.626 , 0.6235,\n",
       "        0.625 , 0.6195, 0.622 , 0.6195, 0.6225, 0.615 , 0.62  , 0.615 ,\n",
       "        0.623 , 0.612 , 0.619 , 0.612 ]),\n",
       " 'split2_test_score': array([0.5935, 0.6035, 0.596 , 0.6035, 0.603 , 0.6025, 0.604 , 0.6025,\n",
       "        0.604 , 0.6015, 0.605 , 0.6015, 0.607 , 0.602 , 0.6065, 0.602 ,\n",
       "        0.6075, 0.6015, 0.6085, 0.6015]),\n",
       " 'split3_test_score': array([0.6005, 0.606 , 0.6015, 0.606 , 0.609 , 0.604 , 0.6075, 0.604 ,\n",
       "        0.612 , 0.606 , 0.611 , 0.606 , 0.619 , 0.608 , 0.616 , 0.608 ,\n",
       "        0.618 , 0.611 , 0.619 , 0.611 ]),\n",
       " 'split4_test_score': array([0.5995, 0.6065, 0.6   , 0.6065, 0.6105, 0.608 , 0.611 , 0.608 ,\n",
       "        0.612 , 0.608 , 0.6135, 0.608 , 0.616 , 0.604 , 0.618 , 0.604 ,\n",
       "        0.6175, 0.606 , 0.618 , 0.606 ]),\n",
       " 'mean_test_score': array([0.6046, 0.6115, 0.6056, 0.6115, 0.6134, 0.6109, 0.6134, 0.6109,\n",
       "        0.6148, 0.6106, 0.6145, 0.6106, 0.616 , 0.6087, 0.6154, 0.6087,\n",
       "        0.6163, 0.6088, 0.6155, 0.6088]),\n",
       " 'std_test_score': array([0.00903549, 0.00762234, 0.00842259, 0.00762234, 0.00784474,\n",
       "        0.00795864, 0.00792086, 0.00795864, 0.0074135 , 0.00699571,\n",
       "        0.0063561 , 0.00699571, 0.00514782, 0.0053066 , 0.00466262,\n",
       "        0.0053066 , 0.00504579, 0.00443396, 0.00414729, 0.00443396]),\n",
       " 'rank_test_score': array([20,  9, 19,  9,  7, 11,  7, 11,  5, 13,  6, 13,  2, 17,  4, 17,  1,\n",
       "        15,  3, 15])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression parameters\n",
    "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'LogR_tfidf__use_idf': (True, False),\n",
    "               'LogR_tfidf__smooth_idf': (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4527fe1f-b225-4e2f-a1ba-6e25427372e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py:542: FitFailedWarning: \n",
      "100 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py\", line 1351, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py\", line 325, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py\", line 1216, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_base.py\", line 1047, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [   nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      " 0.5814 0.5893 0.5821 0.5893 0.5992 0.5984 0.6014 0.5984 0.6047 0.6031\n",
      " 0.6065 0.6031 0.6063 0.607  0.6071 0.607  0.6076 0.6068 0.6082 0.6068]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hayan\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.39515166, 0.53613505, 0.46541924, 0.30848932, 0.7932415 ,\n",
       "        0.8403564 , 0.79507561, 0.78921242, 1.25976148, 1.45533242,\n",
       "        1.38110485, 1.28953753, 1.94331169, 1.67899246, 1.77556677,\n",
       "        1.84174004, 2.120821  , 2.04415259, 2.11058421, 2.02098465,\n",
       "        0.38659768, 0.43227129, 0.41284575, 0.50077963, 1.01884933,\n",
       "        0.96103616, 1.06247225, 1.07158747, 1.94453149, 2.31135535,\n",
       "        2.7620647 , 2.63665433, 3.08317952, 2.99544549, 2.72082272,\n",
       "        2.23410115, 2.79273458, 2.59300909, 2.67454052, 2.60576797]),\n",
       " 'std_fit_time': array([0.03869222, 0.10698775, 0.19282231, 0.02089596, 0.05000303,\n",
       "        0.03306166, 0.05935648, 0.01746673, 0.05675825, 0.05151279,\n",
       "        0.05714498, 0.02308713, 0.09751565, 0.02697147, 0.05220161,\n",
       "        0.03591047, 0.02256627, 0.04026503, 0.04118468, 0.03327305,\n",
       "        0.01463497, 0.04297378, 0.02414127, 0.07709986, 0.05816285,\n",
       "        0.04953142, 0.05589658, 0.06677874, 0.13224402, 0.33295585,\n",
       "        0.28819307, 0.13002764, 0.21606172, 0.21347725, 0.38536623,\n",
       "        0.04020813, 0.15978749, 0.06207075, 0.09979142, 0.11149618]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.07253847, 0.0822073 , 0.08151126, 0.0814322 , 0.10856199,\n",
       "        0.129107  , 0.13509731, 0.14110436, 0.23476434, 0.27843595,\n",
       "        0.3018034 , 0.27443533, 0.25764308, 0.28207726, 0.21828623,\n",
       "        0.215485  , 0.2428092 , 0.22294617, 0.25173459, 0.21757617]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00970492, 0.01240659, 0.01110629, 0.01201732, 0.00723418,\n",
       "        0.01548158, 0.02019826, 0.03886861, 0.07545779, 0.08231125,\n",
       "        0.07833045, 0.01744517, 0.04061468, 0.03917838, 0.06038247,\n",
       "        0.02526752, 0.0220245 , 0.0207564 , 0.02941767, 0.04362198]),\n",
       " 'param_svm_clf__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5895, 0.5985, 0.5915, 0.5985,\n",
       "        0.6075, 0.6065, 0.611 , 0.6065, 0.611 , 0.607 , 0.6135, 0.607 ,\n",
       "        0.6135, 0.615 , 0.6135, 0.615 , 0.617 , 0.616 , 0.617 , 0.616 ]),\n",
       " 'split1_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5925, 0.6025, 0.591 , 0.6025,\n",
       "        0.622 , 0.6215, 0.625 , 0.6215, 0.624 , 0.6195, 0.6265, 0.6195,\n",
       "        0.6215, 0.623 , 0.622 , 0.623 , 0.6195, 0.622 , 0.6215, 0.622 ]),\n",
       " 'split2_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.571 , 0.576 , 0.5725, 0.576 ,\n",
       "        0.585 , 0.586 , 0.588 , 0.586 , 0.59  , 0.5905, 0.589 , 0.5905,\n",
       "        0.589 , 0.591 , 0.59  , 0.591 , 0.59  , 0.5925, 0.5915, 0.5925]),\n",
       " 'split3_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5725, 0.583 , 0.5725, 0.583 ,\n",
       "        0.5855, 0.5835, 0.586 , 0.5835, 0.5905, 0.5945, 0.593 , 0.5945,\n",
       "        0.5975, 0.5995, 0.5975, 0.5995, 0.5995, 0.598 , 0.5975, 0.598 ]),\n",
       " 'split4_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5815, 0.5865, 0.583 , 0.5865,\n",
       "        0.596 , 0.5945, 0.597 , 0.5945, 0.608 , 0.604 , 0.6105, 0.604 ,\n",
       "        0.61  , 0.6065, 0.6125, 0.6065, 0.612 , 0.6055, 0.6135, 0.6055]),\n",
       " 'mean_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5814, 0.5893, 0.5821, 0.5893,\n",
       "        0.5992, 0.5984, 0.6014, 0.5984, 0.6047, 0.6031, 0.6065, 0.6031,\n",
       "        0.6063, 0.607 , 0.6071, 0.607 , 0.6076, 0.6068, 0.6082, 0.6068]),\n",
       " 'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.0086741 , 0.00983158, 0.00839881, 0.00983158, 0.01405916,\n",
       "        0.01407267, 0.01473228, 0.01407267, 0.01296765, 0.01017546,\n",
       "        0.01380942, 0.01017546, 0.01160431, 0.01124722, 0.01163357,\n",
       "        0.01124722, 0.01117766, 0.01094806, 0.01162583, 0.01094806]),\n",
       " 'rank_test_score': array([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 20, 17, 19, 17, 14, 15, 13, 15, 10, 11,  8, 11,  9,  4,\n",
       "         3,  4,  2,  6,  1,  6])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear SVM \n",
    "parameters = {'svm_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'svm_tfidf__use_idf': (True, False),\n",
    "               'svm_tfidf__smooth_idf': (True, False),\n",
    "               'svm_clf__penalty': ('l1','l2'),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5925343-fbf4-40a0-b8b4-7eeded1b8a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #by running above commands we can find the model with best performing parameters\n",
    "\n",
    "\n",
    "# #running both random forest and logistic regression models again with best parameter found with GridSearch method\n",
    "# random_forest_final = Pipeline([\n",
    "#         ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
    "#         ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
    "#         ])\n",
    "    \n",
    "# random_forest_final.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "# predicted_rf_final = random_forest_final.predict(DataPrep.test_news['Statement'])\n",
    "# np.mean(predicted_rf_final == DataPrep.test_news['Label'])\n",
    "# print(metrics.classification_report(DataPrep.test_news['Label'], predicted_rf_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35660414-99e3-4fb8-a7f0-d2a06b75f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.38      0.48      1169\n",
      "        True       0.61      0.82      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.63      0.60      0.59      2551\n",
      "weighted avg       0.63      0.62      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "logR_pipeline_final = Pipeline([\n",
    "        #('LogRCV',countV_ngram),\n",
    "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_final.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR_final = logR_pipeline_final.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR_final == DataPrep.test_news['Label'])\n",
    "#accuracy = 0.62\n",
    "print(metrics.classification_report(DataPrep.test_news['Label'], predicted_LogR_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b2e70b9-584d-48a4-9556-86af96d98b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "by running both random forest and logistic regression with GridSearch's best parameter estimation, we found that for random \n",
    "forest model with n-gram has better accuracty than with the parameter estimated. The logistic regression model with best parameter \n",
    "has almost similar performance as n-gram model so logistic regression will be out choice of model for prediction.\n",
    "\"\"\"\n",
    "\n",
    "#saving best model to the disk\n",
    "model_file = 'final_model.sav'\n",
    "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93bc32e2-06a1-4f4c-b697-82920cdeba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting learing curve\n",
    "def plot_learing_curve(pipeline,title):\n",
    "    size = 10000\n",
    "    cv = KFold(size, shuffle=True)\n",
    "    \n",
    "    X = DataPrep.train_news[\"Statement\"]\n",
    "    y = DataPrep.train_news[\"Label\"]\n",
    "    \n",
    "    pl = pipeline\n",
    "    pl.fit(X,y)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "       \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "     \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899de3e4-0270-40e4-ad3f-9b0df5704134",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learing_curve(logR_pipeline_ngram,\"Naive-bayes Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7471239-399a-4bd0-b00a-92110dec872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learing_curve(nb_pipeline_ngram,\"LogisticRegression Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed2ab3c-e64e-4d57-a216-6d0f8abe3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learing_curve(svm_pipeline_ngram,\"SVM Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7dade-ff43-403f-b3d5-bf04c40bd473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learing_curve(sgd_pipeline_ngram,\"SGD Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66b683-9a07-41b8-aa6e-38e3c6db7d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_learing_curve(random_forest_ngram,\"RandomForest Classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
